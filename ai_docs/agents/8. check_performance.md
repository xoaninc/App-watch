# Check Performance Agent

Review code for performance issues, especially database queries, memory usage, and algorithmic efficiency.

## Purpose

Identify and prevent performance problems before they reach production, with special focus on database operations given large data volumes.

## When to Use

Run this agent:
- After implementing database-related features
- When adding new queries
- Before merging features that handle large data sets
- When users report slowness

## Prerequisites

Read first:
1. `/ai_docs/architecture/critical-rules.md` - Performance rules
2. `/ai_docs/architecture/application-layer.md` - Query patterns

## Critical Rule

**Database can be HUGE** - Always analyze performance impact before any change.

## Input

- Files to review (paths or git diff)
- Specific queries or methods to analyze
- Or: entire feature branch

## Instructions

### Step 1: N+1 Query Detection

**Check for loops with queries:**
```
// BAD - N+1
for user in users:
    orders = orderRepository.findByUser(user.id)  // N queries!

// GOOD - Batch query
userIds = users.map(u => u.id)
orders = orderRepository.findByUserIds(userIds)  // 1 query
```

**Signs of N+1:**
- Repository calls inside loops
- Query bus calls inside loops
- Lazy loading in loops

### Step 2: Query Analysis

For each query, check:
- [ ] Uses indexes (WHERE clauses on indexed columns)
- [ ] Limits results (pagination)
- [ ] Selects only needed columns
- [ ] Uses JOINs efficiently
- [ ] No SELECT * in production code

### Step 3: Index Verification

For new migrations:
- [ ] Indexes on foreign keys
- [ ] Indexes on frequently filtered columns
- [ ] Composite indexes for common WHERE combinations
- [ ] No over-indexing (too many indexes)

### Step 4: Memory Usage

Check for:
- [ ] Large collections loaded in memory
- [ ] Missing pagination
- [ ] Unbounded queries
- [ ] Large file processing without streaming

### Step 5: Algorithmic Complexity

Check for:
- [ ] Nested loops (O(n²))
- [ ] Unnecessary iterations
- [ ] Repeated calculations
- [ ] Missing caching opportunities

### Step 6: Caching Analysis

Check:
- [ ] Expensive queries cached?
- [ ] Cache invalidation correct?
- [ ] Cache keys unique and consistent?
- [ ] Cache TTL appropriate?

### Step 7: API Performance

Check:
- [ ] Payload sizes reasonable
- [ ] Unnecessary data not returned
- [ ] Pagination implemented
- [ ] Response time expectations met

## Output Format

```markdown
# Performance Review Report

**Files Reviewed:** [count]
**Date:** [date]
**Status:** PASS | FAIL | WARNINGS
**Risk Level:** Low | Medium | High | Critical

---

## Summary

| Category | Status | Issues |
|----------|--------|--------|
| N+1 Queries | PASS/FAIL | [count] |
| Query Efficiency | PASS/FAIL | [count] |
| Indexing | PASS/FAIL | [count] |
| Memory Usage | PASS/FAIL | [count] |
| Algorithm Complexity | PASS/FAIL | [count] |
| Caching | PASS/FAIL | [count] |

---

## Risk Assessment

| Issue | Probability | Impact | Data Volume | Risk |
|-------|-------------|--------|-------------|------|
| [issue] | High/Med/Low | High/Med/Low | [expected rows] | Critical/High/Med/Low |

---

## 1. N+1 Query Issues

### Critical

#### [file:line]
**Code:**
```
[problematic code]
```

**Problem:** Query executed inside loop
**Executions:** N queries where N = [size of collection]
**Impact:** [expected impact at scale]

**Fix:**
```
[corrected code with batch query]
```

---

## 2. Query Efficiency Issues

### [Query Name/Location]

**Current Query:**
```sql
SELECT * FROM users WHERE status = 'active'
```

**Issues:**
- [ ] No index on `status` column
- [ ] SELECT * instead of specific columns
- [ ] No LIMIT clause

**Recommendations:**
1. Add index: `CREATE INDEX idx_users_status ON users(status)`
2. Select only needed columns
3. Add pagination

**Estimated Impact:**
- Current: [X]ms for [Y] rows
- After fix: [X]ms for [Y] rows

---

## 3. Missing Indexes

### Migration: [migration name]

| Table | Column(s) | Reason | Priority |
|-------|-----------|--------|----------|
| [table] | [column] | Filtered in WHERE | High |
| [table] | [col1, col2] | Composite filter | Medium |

**Recommended Indexes:**
```sql
CREATE INDEX idx_[table]_[column] ON [table]([column]);
CREATE INDEX idx_[table]_[cols] ON [table]([col1], [col2]);
```

---

## 4. Memory Issues

### [file:line]
**Code:**
```
users = repository.findAll()  // Loads ALL users!
```

**Problem:** Unbounded query loads entire table
**Expected Rows:** [estimate]
**Memory Impact:** ~[X]MB

**Fix:**
```
users = repository.findPaginated(limit: 100, offset: 0)
```

---

## 5. Algorithm Complexity Issues

### [file:line]
**Current Complexity:** O(n²)
**Code:**
```
for item1 in list1:
    for item2 in list2:
        if item1.id == item2.id:
            // ...
```

**Fix (O(n)):**
```
list2Map = list2.keyBy('id')
for item1 in list1:
    item2 = list2Map.get(item1.id)
    if item2:
        // ...
```

---

## 6. Caching Opportunities

### Cacheable Queries

| Query | Frequency | Cost | Cache Recommendation |
|-------|-----------|------|---------------------|
| [query] | [calls/min] | [ms] | Cache for [X] minutes |

### Missing Cache Invalidation

| Cache Key | Should Invalidate On |
|-----------|---------------------|
| [key] | [event/action] |

---

## Performance Metrics (if measurable)

### Before/After Estimates

| Operation | Before | After | Improvement |
|-----------|--------|-------|-------------|
| [operation] | [X]ms | [Y]ms | [Z]% |

### Scaling Analysis

| Data Size | Current | After Fix |
|-----------|---------|-----------|
| 1K rows | [X]ms | [Y]ms |
| 10K rows | [X]ms | [Y]ms |
| 100K rows | [X]ms | [Y]ms |
| 1M rows | [X]ms | [Y]ms |

---

## Recommendations

### Must Fix (Critical)
1. [N+1 or unbounded query]
2. [Missing critical index]

### Should Fix (High)
1. [Performance improvement]
2. [Caching opportunity]

### Consider (Medium)
1. [Optimization]
2. [Index suggestion]

---

## Testing Recommendations

1. Load test with [X] concurrent users
2. Test with [Y] rows in [table]
3. Monitor query execution times
4. Profile memory usage
```

## Quick Reference: Performance Patterns

### Batch Queries
```
// BAD - N+1
for userId in userIds:
    user = repository.findById(userId)

// GOOD - Batch
users = repository.findByIds(userIds)
usersMap = users.keyBy('id')
```

### Pagination
```
// BAD - Load all
users = repository.findAll()

// GOOD - Paginate
users = repository.findPaginated(
    limit: 50,
    offset: request.page * 50
)
```

### Select Specific Columns
```
// BAD
SELECT * FROM users

// GOOD
SELECT id, name, email FROM users
```

### Eager Loading
```
// BAD - Lazy loading in loop
for order in orders:
    customer = order.customer  // Query per order!

// GOOD - Eager load
orders = orderRepository.findWithCustomers(orderIds)
```

## Red Flags

- `findAll()` without pagination
- Repository calls inside `foreach`/`map`
- `SELECT *` in queries
- No indexes on foreign keys
- Queries without LIMIT
- Large IN clauses (> 1000 items)
- Missing composite indexes for common filters
